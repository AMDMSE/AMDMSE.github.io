<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>AMDM-SE</title>
    
    <meta name="description" content="Project Page for AMDM-SE">
    <meta name="author" content="">

    <link rel="stylesheet" href="style.css" />

    <!-- MathJax for LaTeX-style math -->
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
        </script>

</head>

<!-- 
<head>
  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">    
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/audio-table.css">
  <link rel="stylesheet" type="text/css" href="static/css/dropdown_style.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head> -->

<body>

  <div class="container">
    
    <div class="section-title text-center center">
          <h1 style="color:black"><strong><br><br>AMDM-SE: Attention-based Multichannel Diffusion Model for Speech Enhancement <br><strong></h1>
        <br>
              
        <div class="publication-authors">

        </div>




        
    </div>

    <div class="figures">
    <figure>
        <img src="amdm_arc.png" style="max-width:70%; height:auto; display:block; margin:0 auto;" alt="Block diagram of AMDM-SE">
        <figcaption>
            Network architecture, AMDM-SE in the green frame and Cross Channel TF-Attention in the blue frame.
        </figcaption>
    </figure>
        
    <div class="column-center"> 
        <!-- <img style="border:0px solid black;" src="amdm_arc.png" style="max-width:50%; height:auto; display:block; margin:0 auto; alt="method" class="enlarge-above-other"> -->
        <img src="amdm_arc.png" style="max-width:70%; height:auto; display:block; margin:0 auto;">
        <br><br>
    </div> 
    <div class="row">
      
          <div class="col-md-10 col-md-offset-1">

                <p style="color:black; font-family:Sans-Serif; font-size:16px">  
                    Diffusion models have achieved impressive results in reconstructing images from noisy inputs. By treating speech signals in the time–frequency domain as images, 
                    we can apply similar techniques to speech enhancement. Given the ubiquity of devices equipped with multiple microphones, such as smartphones, laptops, and voice 
                    assistants, we extend a state-of-the-art diffusion-based method to leverage multichannel inputs for further performance gains.
                    We introduce AMDM-SE, an Attention-based Multichannel Diffusion Model for Speech Enhancement, specifically for noise reduction. AMDM-SE harnesses spatial inter-channel
                    information via a cross-channel time–frequency attention block, enabling the network to faithfully reconstruct fine-grained signal details within a generative diffusion framework. 
                    On the CHiME-3 benchmark, AMDM-SE surpasses both the single-channel diffusion baseline and the multichannel model without the attention mechanism,
                    as well as a DNN-based predictive method. Simulated-data experiments further highlight the critical role of our multichannel processing stage.
                    Overall, our results demonstrate that incorporating targeted multichannel attention within diffusion models markedly improves noise reduction performance.
                </p> <br><hr><br>
      
          </div>
    </div>

  </div>
<!-- </div> -->



<script type="text/javascript" src="js/jquery.1.11.1.js"></script> 
<script type="text/javascript" src="js/bootstrap.js"></script> 
<script type="text/javascript" src="js/SmoothScroll.js"></script> 
<script type="text/javascript" src="js/nivo-lightbox.js"></script> 
<script type="text/javascript" src="js/jquery.isotope.js"></script> 
<script type="text/javascript" src="js/jqBootstrapValidation.js"></script> 
<script type="text/javascript" src="js/contact_me.js"></script> 
<script type="text/javascript" src="js/main.js"></script>
</body>
</html>
